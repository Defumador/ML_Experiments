{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch autoencoder for nlp with lstm + cnn ",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manishiitg/ML_Experiments/blob/master/autoencoder/pytorch_autoencoder_for_nlp_with_lstm_%2B_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emLH_VHiiGJW",
        "colab_type": "text"
      },
      "source": [
        "currently stuck on this as unable to do this properly that is getting output. maybe explore cnn etc.\n",
        "\n",
        " **mainly problem is the model predictions unable to convert them back to sentense. i think mainly doing some silly mistakes need to rethink stuff etc and approach with a fresh mind**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PVAvgJ2tRPW",
        "colab_type": "code",
        "outputId": "a8fc0679-9068-4d36-90aa-3ba1f9983c83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy', include_lengths = True)\n",
        "LABEL = data.LabelField(dtype = torch.float)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "categories = [ 'alt.atheism', 'comp.graphics','rec.autos','sci.crypt','talk.politics.guns']\n",
        "news = fetch_20newsgroups(subset=\"train\", categories=categories)\n",
        "\n",
        "max_limit = 4000\n",
        "\n",
        "targets = news[\"target\"][:max_limit]\n",
        "filenames = news[\"filenames\"][:max_limit]\n",
        "news = news[\"data\"][:max_limit]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from torchtext.data import Dataset\n",
        "\n",
        "class NewGroupDataset(Dataset):\n",
        "    def __init__(self, text_field, label_field, **kwargs):\n",
        "        fields = [(\"Description\", text_field), (\"Category\", label_field)]\n",
        "        examples = []\n",
        "        \n",
        "        for idx, n in enumerate(news):\n",
        "          examples.append(data.Example.fromlist([n, targets[idx]], fields))\n",
        "        super().__init__(examples, fields, **kwargs)\n",
        "\n",
        "    @staticmethod\n",
        "    def sort_key(ex): return len(ex.Description)\n",
        "    \n",
        "    @classmethod\n",
        "    def splits(cls, text_field, label_field, root='.data',\n",
        "               train='train', test='test', **kwargs):\n",
        "        return super().splits(\n",
        "            root, text_field=text_field, label_field=label_field,\n",
        "            train=train, validation=None, test=test, **kwargs)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "full_data_set = NewGroupDataset(TEXT, LABEL)\n",
        "print(\"full dataset length\" , len(full_data_set))\n",
        "\n",
        "\n",
        "\n",
        "from torchtext.vocab import Vectors, GloVe\n",
        "\n",
        "vectors = GloVe(name='6B', dim=300)\n",
        "\n",
        "TEXT.build_vocab(full_data_set, vectors=vectors)\n",
        "LABEL.build_vocab(full_data_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "full_data_iterator = data.BucketIterator(full_data_set, \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "full dataset length 2799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj5KYNTxuuuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import random\n",
        "\n",
        "# train_data, test_data = NewGroupDataset.splits(TEXT, LABEL)\n",
        "# train_data, valid_data = train_data.split(random_state = random.seed(SEED))\n",
        "\n",
        "# print(f'Number of training examples: {len(train_data)}')\n",
        "# print(f'Number of validation examples: {len(valid_data)}')\n",
        "# print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ5CbEvxPfh3",
        "colab_type": "code",
        "outputId": "66d1241f-f2f7-487a-a86a-aafa18fb6fc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# print(TEXT.vocab.stoi[200])\n",
        "# print(TEXT.vocab.itos[100])\n",
        "\n",
        "print(TEXT.vocab.vectors.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([53168, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XppDkzsteqQI",
        "colab_type": "code",
        "outputId": "8b43447e-7176-4d61-9acb-1da6c6ca3e03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "# def find_distance():\n",
        "cat=vectors[stoi['cat']]\n",
        "\n",
        "dist = ((vectors-cat)**2).sum(1)\n",
        "dist_sorted, dist_sorted_indexes = dist.sort(0)\n",
        "\n",
        "print([vectors.itos[i] for i in dist_sorted_indexes[0:10]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-8a7c8a9b4544>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdist_sorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist_sorted_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'stoi' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVOdG7-7q2de",
        "colab_type": "code",
        "outputId": "4153ef38-d95d-4f78-d34d-ef78dc9ef8ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class LSTMAutoencoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, latent_dim, n_layers, \n",
        "                 bidirectional, dropout, pad_idx, weights):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        # self.hidden_dim = hidden_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        \n",
        "        self.rnn_encoder = nn.LSTM(embedding_dim, \n",
        "                           latent_dim, \n",
        "                           num_layers=1, \n",
        "                           bidirectional=False)\n",
        "        \n",
        "        # self.fc_encoder = nn.Linear(hidden_dim * 2, latent_dim)\n",
        "\n",
        "        # self.fc_decoder = nn.Linear(latent_dim, hidden_dim * 2)\n",
        "\n",
        "        self.rnn_decoder = nn.LSTM(latent_dim,embedding_dim, \n",
        "                           num_layers=1, \n",
        "                           bidirectional=False)\n",
        "        \n",
        "        # self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        # print(text.shape, \"input text shape\")\n",
        "        # embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        _, (hidden, _) = self.rnn_encoder(text)\n",
        "        # print(hidden.shape , \"hidden shap after encoder rnn\")\n",
        "        \n",
        "\n",
        "        # hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "\n",
        "        # hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
        "        # print(hidden.shape, \"hidden shape after concat\")\n",
        "\n",
        "        # hidden = hidden.unsqueeze(0)\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "\n",
        "        # encoded = F.relu(self.fc_encoder(hidden))\n",
        "        # print(encoded.shape , \"encoder output shape\")\n",
        "\n",
        "        # decoded_fc = F.relu(self.fc_decoder(encoded))\n",
        "        # print(decoded_fc.shape)\n",
        "\n",
        "        encoded_repeat = hidden.repeat(len(text),1,1)\n",
        "        # print(encoded_repeat.shape, \"encode repeat shape\")\n",
        "\n",
        "        decoded, _ = self.rnn_decoder(encoded_repeat)\n",
        "        \n",
        "\n",
        "        # print(decoded.shape, \" decoded output\")\n",
        "            \n",
        "        return decoded\n",
        "\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 256\n",
        "LATENT_DIM = 10\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "\n",
        "\n",
        "model = LSTMAutoencoder(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            LATENT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX,\n",
        "            TEXT.vocab.vectors)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "total_step = len(full_data_iterator)\n",
        "num_epochs = 1\n",
        "\n",
        "learning_rate = .0005\n",
        "\n",
        "# Loss and optimizer\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=.9)\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "\n",
        "embedding_layer = nn.Embedding(INPUT_DIM, EMBEDDING_DIM, padding_idx = PAD_IDX)\n",
        "embedding_layer.weight = nn.Parameter(TEXT.vocab.vectors, requires_grad=False)\n",
        "\n",
        "\n",
        "embedding_layer.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "embedding_layer.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "embedding_layer.to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def word_ids_to_sentence(id_tensor, vocab, join=None):\n",
        "    \"\"\"Converts a sequence of word ids to a sentence\"\"\"\n",
        "    if isinstance(id_tensor, torch.LongTensor):\n",
        "        ids = id_tensor.transpose(0, 1).contiguous().view(-1)\n",
        "    elif isinstance(id_tensor, np.ndarray):\n",
        "        ids = id_tensor.transpose().reshape(-1)\n",
        "    batch = [vocab.itos[ind] for ind in ids] # denumericalize\n",
        "    if join is None:\n",
        "        return batch\n",
        "    else:\n",
        "        return join.join(batch)\n",
        "\n",
        "i = 0\n",
        "# for epoch in range(num_epochs):\n",
        "for batch in full_data_iterator:\n",
        "    optimizer.zero_grad()\n",
        "    text, text_lengths = batch.Description\n",
        "    text = text.to(device)\n",
        "    text_lengths = text_lengths.to(device)\n",
        "\n",
        "    print(text.shape, \"text shape\")\n",
        "\n",
        "    print(word_ids_to_sentence(text[75].cpu().data.numpy(), TEXT.vocab))\n",
        "\n",
        "    embedded = embedding_layer(text)\n",
        "    # print(embedded.shape, \"text embedding shape\")\n",
        "    # packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "\n",
        "    # print(packed_embedded)\n",
        "    \n",
        "    predictions = model(embedded)\n",
        "\n",
        "    # predictions = nn.utils.rnn.pad_packed_sequence(predictions)\n",
        "\n",
        "    print(predictions.shape, \"predictions shape\")\n",
        "\n",
        "    predictions2 = predictions.transpose(1,0)\n",
        "    print(predictions2.shape, \"prediction2s shape\")  \n",
        "\n",
        "    print(predictions2[0][:][1])\n",
        "\n",
        "    # print(text.shape, \"text shape\")\n",
        "    loss = criterion(predictions, embedded)\n",
        "    \n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    i+=1\n",
        "    break \n",
        "    print ('Batch [{}], Loss: {:.4f}' \n",
        "            .format(i, loss.item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([90, 64]) text shape\n",
            "['the', 'sale', 'as', 'applied', 'L.', 'it', '\"', 'lvandyke@balboa.eng.uci.edu', 'hell', 'have', 'khan0095@nova.gmi.edu', '3', 'that', 'those', 'starts', '?', ',', 'Geo', 'It', 'is', 'is', 'work', '?', 'be', 'resolution', '....', 'never', 'deposit', 'rest', '\\n   ', 'Sorry', ',', 'for', 'Thanks', 'Engineering', '?', '.', 'monitor', 'o', '...', ')', \"'\", '\\n\\n', '....', 'Never', '\\n', 'appreciated', 'Richard', 'Thanks', '\\n\\n', 'advance', '\\n\\n\\n', '.', '!', '\\n\\n\\n\\n\\n\\t', ' ', '\\n\\n', '\\n', 'Ron', 'George', 'then', ')', '.', '<pad>']\n",
            "torch.Size([90, 64, 300]) predictions shape\n",
            "torch.Size([64, 90, 300]) prediction2s shape\n",
            "tensor([-0.0240, -0.0155, -0.0138, -0.0453, -0.0203, -0.0279,  0.0005, -0.0064,\n",
            "        -0.0359,  0.0103,  0.0248,  0.0025, -0.0019,  0.0049, -0.0339,  0.0279,\n",
            "         0.0011,  0.0019, -0.0181, -0.0179,  0.0199,  0.0064, -0.0050,  0.0017,\n",
            "         0.0176,  0.0071, -0.0221, -0.0138, -0.0152,  0.0047,  0.0014,  0.0157,\n",
            "        -0.0162,  0.0084,  0.0131,  0.0139, -0.0128,  0.0019, -0.0279,  0.0099,\n",
            "        -0.0283,  0.0356,  0.0150,  0.0086,  0.0072, -0.0264,  0.0109, -0.0122,\n",
            "         0.0192,  0.0235, -0.0106, -0.0037,  0.0196, -0.0185,  0.0311,  0.0270,\n",
            "         0.0374, -0.0252, -0.0203,  0.0531,  0.0206, -0.0228,  0.0079, -0.0105,\n",
            "        -0.0347,  0.0236,  0.0038, -0.0463, -0.0315, -0.0265,  0.0186, -0.0023,\n",
            "        -0.0112, -0.0385,  0.0002, -0.0237,  0.0088, -0.0287, -0.0071,  0.0018,\n",
            "         0.0052, -0.0177,  0.0165,  0.0156,  0.0156,  0.0080, -0.0302,  0.0106,\n",
            "         0.0056, -0.0187, -0.0219,  0.0010,  0.0223,  0.0040, -0.0200,  0.0170,\n",
            "        -0.0261, -0.0005, -0.0107, -0.0011,  0.0040, -0.0222, -0.0177,  0.0160,\n",
            "        -0.0186, -0.0077, -0.0274,  0.0155, -0.0002,  0.0098,  0.0034,  0.0196,\n",
            "         0.0172,  0.0048,  0.0214,  0.0090,  0.0423, -0.0023,  0.0202,  0.0457,\n",
            "         0.0053, -0.0177, -0.0035,  0.0103, -0.0104,  0.0008,  0.0129,  0.0152,\n",
            "        -0.0133, -0.0150,  0.0049, -0.0086, -0.0033, -0.0175, -0.0117,  0.0234,\n",
            "         0.0091,  0.0051,  0.0066,  0.0002, -0.0144,  0.0244,  0.0023, -0.0390,\n",
            "        -0.0079,  0.0032,  0.0009,  0.0210,  0.0032, -0.0037,  0.0406, -0.0093,\n",
            "        -0.0371,  0.0237, -0.0141,  0.0002, -0.0389,  0.0159,  0.0174,  0.0201,\n",
            "        -0.0163, -0.0314,  0.0170,  0.0095,  0.0339,  0.0167, -0.0282,  0.0116,\n",
            "        -0.0060, -0.0049,  0.0329, -0.0236,  0.0016, -0.0065, -0.0067,  0.0188,\n",
            "         0.0161, -0.0064,  0.0038, -0.0342,  0.0089, -0.0160, -0.0272,  0.0296,\n",
            "         0.0055,  0.0053, -0.0134, -0.0082,  0.0096,  0.0104, -0.0293,  0.0035,\n",
            "        -0.0256, -0.0137,  0.0017,  0.0047, -0.0090,  0.0232,  0.0247,  0.0109,\n",
            "        -0.0327,  0.0117,  0.0023, -0.0041,  0.0114, -0.0032,  0.0067,  0.0323,\n",
            "         0.0204,  0.0019, -0.0120, -0.0171, -0.0311, -0.0236, -0.0093, -0.0098,\n",
            "        -0.0089, -0.0057,  0.0242, -0.0029,  0.0248, -0.0084, -0.0352, -0.0132,\n",
            "        -0.0126,  0.0214, -0.0106, -0.0069,  0.0134, -0.0012, -0.0089,  0.0208,\n",
            "        -0.0036,  0.0052, -0.0348, -0.0024,  0.0113,  0.0233,  0.0155,  0.0138,\n",
            "        -0.0074,  0.0340, -0.0223, -0.0041,  0.0016, -0.0107, -0.0413,  0.0273,\n",
            "         0.0129, -0.0025,  0.0099, -0.0075,  0.0248,  0.0091,  0.0099,  0.0116,\n",
            "         0.0147,  0.0060,  0.0042, -0.0234,  0.0092, -0.0379, -0.0185, -0.0013,\n",
            "        -0.0084, -0.0091,  0.0259, -0.0032,  0.0162, -0.0061, -0.0141, -0.0018,\n",
            "         0.0166, -0.0004, -0.0077, -0.0115,  0.0332,  0.0055,  0.0020,  0.0093,\n",
            "        -0.0329,  0.0023,  0.0214,  0.0013,  0.0229,  0.0407,  0.0107, -0.0127,\n",
            "        -0.0293,  0.0105,  0.0376,  0.0173, -0.0086, -0.0057,  0.0199, -0.0182,\n",
            "        -0.0347, -0.0083,  0.0219,  0.0280], grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ax3Jp-r0GVlC",
        "colab_type": "code",
        "outputId": "f2734e77-2a23-4496-e1b0-390f14dd486f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class LSTMAutoencoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, latent_dim, n_layers, \n",
        "                 bidirectional, dropout, pad_idx, weights):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "\n",
        "        self.embedding.weight = nn.Parameter(weights, requires_grad=False)\n",
        "        \n",
        "        self.rnn_encoder = nn.LSTM(embedding_dim, \n",
        "                           latent_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout)\n",
        "        \n",
        "        # self.fc_encoder = nn.Linear(hidden_dim * 2, latent_dim)\n",
        "\n",
        "        # self.fc_decoder = nn.Linear(latent_dim, hidden_dim * 2)\n",
        "\n",
        "        self.rnn_decoder = nn.LSTM(latent_dim*2,embedding_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout)\n",
        "        \n",
        "        # self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        print(text.shape, \"input text shape\")\n",
        "        # embedded = self.dropout(self.embedding(text))\n",
        "        embedded = self.embedding(text)\n",
        "        print(embedded.shape, \"text embedding shape\")\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "        _, (hidden, _) = self.rnn_encoder(packed_embedded)\n",
        "        print(hidden.shape , \"hidden shap after encoder rnn\")\n",
        "        # _, _ = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "        # hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "\n",
        "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
        "        print(hidden.shape, \"hidden shape after concat\")\n",
        "\n",
        "        hidden = hidden.unsqueeze(0)\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "\n",
        "        # encoded = F.relu(self.fc_encoder(hidden))\n",
        "        # print(encoded.shape , \"encoder output shape\")\n",
        "\n",
        "        # decoded_fc = F.relu(self.fc_decoder(encoded))\n",
        "        # print(decoded_fc.shape)\n",
        "\n",
        "        encoded_repeat = hidden.repeat(self.latent_dim,1,1)\n",
        "        print(encoded_repeat.shape, \"encode repeat shape\")\n",
        "\n",
        "        decoded, _ = self.rnn_decoder(encoded_repeat)\n",
        "        \n",
        "\n",
        "        print(decoded.shape, \" decoded output\")\n",
        "            \n",
        "        return decoded\n",
        "\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 256\n",
        "LATENT_DIM = 10\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "\n",
        "\n",
        "model = LSTMAutoencoder(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            LATENT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX,\n",
        "            TEXT.vocab.vectors)\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "# Train the model\n",
        "total_step = len(full_data_iterator)\n",
        "num_epochs = 1\n",
        "\n",
        "learning_rate = .0005\n",
        "\n",
        "# Loss and optimizer\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=.9)\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in full_data_iterator:\n",
        "        optimizer.zero_grad()\n",
        "        text, text_lengths = batch.Description\n",
        "        text = text.to(device)\n",
        "        text_lengths = text_lengths.to(device)\n",
        "        \n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "\n",
        "        print(predictions.shape)\n",
        "        print(text.shape)\n",
        "        loss = criterion(predictions, text)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-dd26d5f1db53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mtext_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtext_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPAD_IDX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: to() received an invalid combination of arguments - got (torch.device, padding_idx=int), but expected one of:\n * (torch.device device, torch.dtype dtype, bool non_blocking, bool copy)\n * (torch.dtype dtype, bool non_blocking, bool copy)\n * (Tensor tensor, bool non_blocking, bool copy)\n"
          ]
        }
      ]
    }
  ]
}